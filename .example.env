[settings]

# Local Database
export PRIMARY_DATABASE = postgresql+psycopg2://postgres:postgres@localhost/lmi
export SECONDARY_DATABASE = "postgresql+psycopg2://postgres:postgres@localhost/test2"

# Allowed Origins
export ORIGINS = ["*"]

# Docker variables
export IMAGE_NAME="your-api-image-name"
export SERVER_VERSION="1.0.0"
export CONTAINER_NAME="your-api-container-name"
export DOCKER_WEB_PORT_FORWARD=8000

# Rabbitmq
#                  protocol;//username:password@ip/virtual_host
export RABBIT_URL="amqp://guest:guest@localhost"
export RABBIT_CONTAINER_NAME = "rabbit_local"
# USE WHEN BUILD WITH DOCKER
# RABBITMQ_URL="amqp://guest:guest@rabbit_local:5672/hml"

# Celery worker
export CELERY_CONTAINER_NAME = "celery_workers_dev"
export CELERY_BACKEND = "db+postgresql://postgres:postgres@localhost/lmi"
 
# Docker settings
export NETWORK_STAGE="main_server_nw"


# - - - - - - - - - -
# BROKER SETTINGS
# - - - - - - - - - -

# BROKER_URL = os.environ['APP_BROKER_URL']
export BROKER_HEARTBEAT = 10
export BROKER_HEARTBEAT_CHECKRATE = 2.0

# Setting BROKER_POOL_LIMIT to None disables pooling
# Disabling pooling causes open/close connections for every task.
# However, the rabbitMQ cluster being behind an Elastic Load Balancer,
# the pooling is not working correctly,
# and the connection is lost at some point.
# There seems no other way around it for the time being.
export BROKER_POOL_LIMIT = None
export BROKER_TRANSPORT_OPTIONS = {'confirm_publish': True}
export BROKER_CONNECTION_TIMEOUT = 20
export BROKER_CONNECTION_RETRY = True
export BROKER_CONNECTION_MAX_RETRIES = 100